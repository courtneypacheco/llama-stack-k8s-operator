name: Build CPU-only vLLM Image

on:
  workflow_dispatch:

permissions:
  actions: write
  contents: read

env:
  VLLM_CPU_IMAGE: "quay.io/llamastack/vllm-cpu"

jobs:
  build-latest-vllm-cpu-image:
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout code
        uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3.6.0

      # We need to clone vLLM first to identify latest tags unless we want to use the GH API.
      - name: Clone vLLM
        uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3.6.0
        with:
          repository: vllm-project/vllm
          path: vllm
          fetch-depth: 0 # Fetch all history to find the latest tag

      - name: Get latest vLLM release tag
        id: get_latest_vllm_release
        run: |
          cd vllm
          LATEST_TAG=$(git describe --tags `git rev-list --tags --max-count=1`)
          echo "::set-output name=tag::${LATEST_TAG}"

      - name: Checkout latest vLLM release
        run: cd vllm && git checkout tags/${{ steps.get_latest_vllm_release.outputs.tag }}
        shell: bash

      - name: Login to Quay.io
        uses: docker/login-action@465a07811f14bebb1938fbed4728c6a1ff8901fc # v2.2.0
        with:
          registry: quay.io
          username: ${{ secrets.APP_QUAY_USERNAME }}
          password: ${{ secrets.APP_QUAY_TOKEN }}

      - name: Build and push latest vLLM CPU image
        run: |
           cd vllm
           podman build --security-opt label=disable -f docker/Dockerfile.cpu --build-arg VLLM_CPU_AVX512BF16=false  --build-arg VLLM_CPU_AVX512VNNI=false --tag ${VLLM_CPU_IMAGE}:latest --target vllm-openai .
           podman tag ${VLLM_CPU_IMAGE}:latest ${VLLM_CPU_IMAGE}:${{ steps.get_latest_vllm_release.outputs.tag }}
           cd ..
           make image-push -e IMG=${VLLM_CPU_IMAGE}:latest
           make image-push -e IMG=${VLLM_CPU_IMAGE}:${{ steps.get_latest_vllm_release.outputs.tag }}
        shell: bash
